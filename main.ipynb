{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908099f6-cdd8-4b02-83bb-eff2d9919f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa25c2-2a19-437e-9e27-01ab3c5673f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa75cd0-6571-4ed4-82ab-8807e3e0fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing dodgy images\n",
    "\n",
    "extensions = ['jpeg', 'jpg', 'bmp', 'png']\n",
    "\n",
    "for folder in os.listdir('pics'):\n",
    "    if folder != '.DS_Store':\n",
    "        for image in os.listdir(os.path.join('pics', folder)):\n",
    "            img_path = os.path.join('pics', folder, image)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                ext = imghdr.what(img_path)\n",
    "                if ext not in extensions:\n",
    "                    print('Image not in extensions list {}'.format(img_path))\n",
    "                    os.remove(img_path)\n",
    "            except Exception as e:\n",
    "                print('Problem with image {}'.format(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2035c75-1ca3-49aa-9b99-544ac0831722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c86368-05fb-4cf3-b167-24c6256b43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data = tf.keras.utils.image_dataset_from_directory('pics')\n",
    "data_iterator = data.as_numpy_iterator() # in order to loop through our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cccaadf-c949-468d-ada8-760f8957bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a batch of data\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ac372-aba4-4947-af18-de364022a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0] # images represented as numpy arrays\n",
    "batch[0].shape # taken in batches of 32 with 256x256 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeaaad2-ead9-42a0-b500-cebd0e0683fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1] # images in the batch classified into sad/happy people based on binary values.\n",
    "         # 1 for sad, 0 for happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa15c1-1dc9-461a-9d08-7c48f3765fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the images\n",
    "fig, ax = plt.subplots(ncols = 4, figsize = (20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2bedf9-d309-4fb9-ac3f-4b2d456123d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "data = data.map(lambda x, y: (x/255, y))\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d0a0b-c2e5-49ee-978e-097141a98ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the scaled images\n",
    "fig, ax = plt.subplots(ncols = 4, figsize = (20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6359d91-85f0-4eea-bb74-253b155e7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "\n",
    "len(data) # 6 batches\n",
    "\n",
    "train_size = int(len(data) * .7) # roughly dividing our data by alloting 70% to training the model\n",
    "val_size = int(len(data) * .2)   # 20% for validation (evaluating the model)\n",
    "test_size = int(len(data) * .1) + 1 # 10% to testing the data\n",
    "\n",
    "train_size + val_size + test_size # checking if it equals len(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf3d55bd-7f75-4b56-9eb7-e1d602d22d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9f300eb-2e02-44a5-a5d9-1ec07d24bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c8146a3-d0c3-4571-9867-6e16df412475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing the deep learning model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a1f02-5ba2-4279-ac52-a3f27e51562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3, 3), 1, activation = 'relu', input_shape = (256, 256, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add (Dense(256, activation = 'relu'))\n",
    "model.add (Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f903cf-9fe5-4b80-810e-86b9e77960ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss = tf.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c8b8a-7a1d-4971-8873-548041ec8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the data\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)\n",
    "hist = model.fit(train, epochs = 20, validation_data = val, callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c3a36-1073-47be-b591-830f07375530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the performance for loss\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color = 'red', label = 'loss') \n",
    "plt.plot(hist.history['val_loss'], color = 'orange', label = 'val_loss')\n",
    "fig.suptitle('Loss', fontsize = 20)\n",
    "plt.legend (loc = \"upper left\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ac78e-6383-49f7-b61b-1fbd9c9133f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the performance for accuracy\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color = 'blue', label = 'accuracy') \n",
    "plt.plot(hist.history['val_accuracy'], color = 'teal', label = 'val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize = 20)\n",
    "plt.legend (loc = \"upper left\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3d8d6ef-1b5c-474e-bfbc-8ea0c0a73b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabf786-9881-4598-994e-131ba86f2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating our model on the test data\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    yhat = model.predict(x)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9655f-8435-41d0-b97d-3c6997b5ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precison: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c26128-e5be-4cc7-aaa9-fd29825b186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing our model on new pictures outside the dataset\n",
    "img = cv2.imread('sadtest.jpg')\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d39e3a-8ecf-4baa-b7c5-ab6552810559",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize / 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb22b64-c711-446d-bbad-62f5df857ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat > 0.5:\n",
    "    print('Predicted class is sad.')\n",
    "else:\n",
    "    print('Predicted class is happy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "514542f1-64fd-4ebf-ae95-876766f580c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f7546-2770-4982-81b0-b20f80577d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "model.save(os.path.join('models', 'happy_or_sad_classification.h5'))\n",
    "new_model = load_model(os.path.join('models', 'happy_or_sad_classification.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
